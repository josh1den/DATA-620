{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa1cd4e",
   "metadata": {},
   "source": [
    "# Project 3: Gender Classifier\n",
    "## Josh Iden\n",
    "### 3/21/23\n",
    "\n",
    "## Assignment Overview\n",
    "\n",
    "![](PJ3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281b002",
   "metadata": {},
   "source": [
    "## Step 1: Load and Split the Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7ddde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import names\n",
    "import random\n",
    "\n",
    "labeled_names = ([(name.lower().strip(), 'male') for name in names.words('male.txt')] + [(name.lower().strip(), 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0acd1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92c7320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the names\n",
    "test_names, dev_names, train_names = labeled_names[:500], labeled_names[500:1000], labeled_names[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b12483f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing set words: 500\n",
      "dev test set word: 500\n",
      "training set words: 6944\n"
     ]
    }
   ],
   "source": [
    "print(\"testing set words: {}\".format(len(test_names)))\n",
    "print(\"dev test set word: {}\".format(len(dev_names)))\n",
    "print(\"training set words: {}\".format(len(train_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57652ee",
   "metadata": {},
   "source": [
    "## Steps 2-3: Make Improvements to Gender Classifier\n",
    "\n",
    "For this assignment, I am using the `nltk.NaiveBayesClassifier()` function. From NLTK [Chapter 6](https://www.nltk.org/book/ch06.html):\n",
    "\n",
    "*In naive Bayes classifiers, every feature gets a say in determining which label should be assigned to a given input value. To choose a label for an input value, the naive Bayes classifier begins by calculating the prior probability of each label, which is determined by checking frequency of each label in the training set. The contribution from each feature is then combined with this prior probability, to arrive at a likelihood estimate for each label. The label whose likelihood estimate is the highest is then assigned to the input value.*\n",
    "\n",
    "Before we can use the classifier, however, we'll need to define and encode a set of relevant features. We'll start with a \"kitchen sink\" approach:\n",
    "\n",
    "### **Kitchen Sink Iteration: v1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425c71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bac5ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training and testing sets for the classifier\n",
    "from nltk.classify import apply_features\n",
    "\n",
    "train_set = apply_features(gender_features, train_names)\n",
    "devtest_set = apply_features(gender_features, dev_names)\n",
    "test_set = apply_features(gender_features, test_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae4cd48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 0.776\n"
     ]
    }
   ],
   "source": [
    "# train the classifier and test using devtest set \n",
    "v1_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "v1_score = nltk.classify.accuracy(v1_classifier, devtest_set)\n",
    "print(\"v1:\",v1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9925bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will keep a running tally of version accuracies\n",
    "total = []\n",
    "\n",
    "def running_tally(version, list):\n",
    "    '''appends a value to a provided list and provides a running tally'''\n",
    "    list.append(version)\n",
    "    for i in range(1,len(list)+1):\n",
    "        print(\"v{}: {}\".format(i, list[i-1]))\n",
    "     \n",
    "    if len(list) > 1:\n",
    "        print(\"best version: v{}, {}\".format(list.index(max(list))+1, max(list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b5e7d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 0.776\n"
     ]
    }
   ],
   "source": [
    "running_tally(v1_score, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df55991",
   "metadata": {},
   "source": [
    "Using the dev-test set, we can generate a list of the errors that the classifier makes when predicting name genders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f65747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "errors = []\n",
    "\n",
    "for (name, tag) in dev_names:\n",
    "    guess = v1_classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "         errors.append( (tag, guess, name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17a36be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------------+\n",
      "| Correct   | Guess   | Name       |\n",
      "+===========+=========+============+\n",
      "| male      | female  | corrie     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | earle      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | rosette    |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | suellen    |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | keil       |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | trude      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | phyllys    |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | obie       |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | luke       |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | pier       |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | nealy      |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | cammy      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | zorah      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | dore       |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | charo      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | dody       |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | mickey     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | reece      |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | marietta   |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | con        |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | babs       |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | hailey     |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | gypsy      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | bliss      |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | elnar      |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | karel      |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | avery      |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | hannibal   |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | hillel     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | matias     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | elias      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | sophey     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | nate       |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | tremaine   |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | neddie     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | orville    |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | suzette    |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | mace       |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | jimmie     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | nathaniel  |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | paddie     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | ray        |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | stillman   |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | see        |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | juliet     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | claybourne |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | lizbeth    |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | dave       |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | scarface   |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | isobel     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | luce       |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | siouxie    |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | marshal    |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | anton      |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | vince      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | lucky      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | tiffany    |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | tarrance   |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | kalle      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | rhodie     |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | hatty      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | robbyn     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | frankie    |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | bobbette   |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | haleigh    |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | jody       |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | al         |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | binky      |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | hassan     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | kalvin     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | arel       |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | gerry      |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | elmore     |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | toby       |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | pen        |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | rosalynd   |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | revkah     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | linoel     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | danny      |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | davy       |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | fallon     |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | ingeberg   |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | augie      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | gwenneth   |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | jedediah   |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | jewel      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | corny      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | glen       |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | dorene     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | harlin     |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | koren      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | margot     |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | tove       |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | dani       |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | maurise    |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | michael    |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | cecil      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | audry      |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | kennedy    |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | neil       |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | matthieu   |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | mattie     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | matt       |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | berry      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | em         |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | dillon     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | bailie     |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | becky      |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | philis     |\n",
      "+-----------+---------+------------+\n",
      "| male      | female  | alex       |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | jeniffer   |\n",
      "+-----------+---------+------------+\n",
      "| female    | male    | hortense   |\n",
      "+-----------+---------+------------+\n"
     ]
    }
   ],
   "source": [
    "header = ['Correct','Guess','Name']\n",
    "print(tabulate(errors, header, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9975cfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     35.5 : 1.0\n",
      "             last_letter = 'k'              male : female =     30.4 : 1.0\n",
      "             last_letter = 'f'              male : female =     14.0 : 1.0\n",
      "             last_letter = 'd'              male : female =     10.6 : 1.0\n",
      "             last_letter = 'v'              male : female =      9.9 : 1.0\n",
      "             last_letter = 'p'              male : female =      9.2 : 1.0\n",
      "             last_letter = 'm'              male : female =      8.8 : 1.0\n",
      "                count(v) = 2              female : male   =      8.8 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.6 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "v1_classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e2733",
   "metadata": {},
   "source": [
    "Let's add single and multiple letter suffixes to the features and see if it improves the classifier accuracy. As the book states, *Each time the error analysis procedure is repeated, we should select a different dev-test/training split, to ensure that the classifier does not start to reflect idiosyncrasies in the dev-test set.* - so we will incorporate this into our workflow. \n",
    "\n",
    "### **Iteration: v2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e479bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labeled_names)\n",
    "test_names, dev_names, train_names = labeled_names[:500], labeled_names[500:1000], labeled_names[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "004c6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"suffix1\"] = name[-1:].lower()\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39d6cfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2: 0.76\n",
      "Difference from previous result: -0.016\n"
     ]
    }
   ],
   "source": [
    "train_set = apply_features(gender_features, train_names)\n",
    "devtest_set = apply_features(gender_features, dev_names)\n",
    "test_set = apply_features(gender_features, test_names)\n",
    "\n",
    "# train the classifier and test using devtest set \n",
    "v2_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "v2_score = nltk.classify.accuracy(v2_classifier, devtest_set)\n",
    "diff = round(v2_score - v1_score, 6)\n",
    "print(\"v2:\",v2_score)\n",
    "print(\"Difference from previous result: {}\".format(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fafd553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 0.776\n",
      "v2: 0.76\n",
      "best version: v1, 0.776\n"
     ]
    }
   ],
   "source": [
    "running_tally(v2_score, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f40974b",
   "metadata": {},
   "source": [
    "We see that this improves the model by nearly two percentage points. There were a few errors that had names with hyphens in them. Let's see if we can add those to a list of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d2c7d",
   "metadata": {},
   "source": [
    "Some names have hyphens. Let's see if adding feature `hyphen` improves the model:\n",
    "\n",
    "### **Iteration: v3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd2d041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labeled_names)\n",
    "test_names, dev_names, train_names = labeled_names[:500], labeled_names[500:1000], labeled_names[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2543f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"suffix1\"] = name[-1:].lower()\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    for name in name:\n",
    "        if re.match('(?:\\w+-)+\\w+', name):\n",
    "            features[\"hyphen\"] = \"yes\"\n",
    "        else:\n",
    "            features[\"hyphen\"] = \"no\"\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f937d660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3: 0.79\n",
      "Difference from previous result: 0.03\n"
     ]
    }
   ],
   "source": [
    "train_set = apply_features(gender_features, train_names)\n",
    "devtest_set = apply_features(gender_features, dev_names)\n",
    "test_set = apply_features(gender_features, test_names)\n",
    "\n",
    "# train the classifier and test using devtest set \n",
    "v3_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "v3_score = nltk.classify.accuracy(v3_classifier, devtest_set)\n",
    "diff = round(v3_score - v2_score, 6)\n",
    "print(\"v3:\",v3_score)\n",
    "print(\"Difference from previous result: {}\".format(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5a79cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 0.776\n",
      "v2: 0.76\n",
      "v3: 0.79\n",
      "best version: v3, 0.79\n"
     ]
    }
   ],
   "source": [
    "running_tally(v3_score, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e0067",
   "metadata": {},
   "source": [
    "This returns the same accuracy score as the previous model. I'm going to remove as it doesn't seem to have significance towards the model and I don't want to overfit. \n",
    "\n",
    "Let's add the name length as a feature and try again:\n",
    "\n",
    "### **Iteration: v4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cd2e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labeled_names)\n",
    "test_names, dev_names, train_names = labeled_names[:500], labeled_names[500:1000], labeled_names[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fea14618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"suffix1\"] = name[-1:].lower()\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    features[\"total_letters\"] = len(name) \n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f13746ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n",
      "Difference from previous result: -0.01\n"
     ]
    }
   ],
   "source": [
    "train_set = apply_features(gender_features, train_names)\n",
    "devtest_set = apply_features(gender_features, dev_names)\n",
    "test_set = apply_features(gender_features, test_names)\n",
    "\n",
    "# train the classifier and test using devtest set \n",
    "v4_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "v4_score = nltk.classify.accuracy(v4_classifier, devtest_set)\n",
    "diff = round(v4_score - v3_score, 6)\n",
    "print(v4_score)\n",
    "print(\"Difference from previous result: {}\".format(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8557a08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 0.776\n",
      "v2: 0.76\n",
      "v3: 0.79\n",
      "v4: 0.78\n",
      "best version: v3, 0.79\n"
     ]
    }
   ],
   "source": [
    "running_tally(v4_score, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b4f4de",
   "metadata": {},
   "source": [
    "This produces a *worse* model. This might be because total letters might be redundant considering we are already tallying individual letters. Let's try using the `nltk` SyllableTokenizer to see if we can create a feature on number of syllables.\n",
    "\n",
    "### **Iteration: v5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d56fe264",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labeled_names)\n",
    "test_names, dev_names, train_names = labeled_names[:500], labeled_names[500:1000], labeled_names[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f253978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.sonority_sequencing import SyllableTokenizer\n",
    "\n",
    "# instantiate the syllable tokenizer\n",
    "st = SyllableTokenizer()\n",
    "\n",
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"suffix1\"] = name[-1:].lower()\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    features[\"syllables\"] = len(st.tokenize(name)) \n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c59a1245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshiden/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: ' '\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778\n",
      "diff from previous: -0.002\n"
     ]
    }
   ],
   "source": [
    "train_set = apply_features(gender_features, train_names)\n",
    "devtest_set = apply_features(gender_features, dev_names)\n",
    "test_set = apply_features(gender_features, test_names)\n",
    "\n",
    "# train the classifier and test using devtest set \n",
    "v5_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "v5_score = nltk.classify.accuracy(v5_classifier, devtest_set)\n",
    "diff = round(v5_score - v4_score, 6)\n",
    "print(v5_score)\n",
    "print(\"diff from previous: {}\".format(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29c63435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 0.776\n",
      "v2: 0.76\n",
      "v3: 0.79\n",
      "v4: 0.78\n",
      "v5: 0.778\n",
      "best version: v3, 0.79\n"
     ]
    }
   ],
   "source": [
    "running_tally(v5_score, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb1676b",
   "metadata": {},
   "source": [
    "Adding `syllables` improves the model, although this fluctuates every time I run the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca482e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 suffix2 = 'na'           female : male   =     95.9 : 1.0\n",
      "                 suffix2 = 'la'           female : male   =     67.9 : 1.0\n",
      "                 suffix2 = 'ia'           female : male   =     50.8 : 1.0\n",
      "             last_letter = 'a'            female : male   =     34.5 : 1.0\n",
      "                 suffix1 = 'a'            female : male   =     34.5 : 1.0\n",
      "                 suffix2 = 'sa'           female : male   =     32.5 : 1.0\n",
      "             last_letter = 'k'              male : female =     29.5 : 1.0\n",
      "                 suffix1 = 'k'              male : female =     29.5 : 1.0\n",
      "                 suffix2 = 'rd'             male : female =     28.9 : 1.0\n",
      "                 suffix2 = 'rt'             male : female =     24.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "v5_classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516af40",
   "metadata": {},
   "source": [
    "### **Iteration: v6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "354a4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labeled_names)\n",
    "test_names, dev_names, train_names = labeled_names[:500], labeled_names[500:1000], labeled_names[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "162b6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"suffix1\"] = name[-1:].lower()\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    features[\"syllables\"] = len(st.tokenize(name)) \n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    \n",
    "    for name in name:\n",
    "        if re.match('.+[aeiou]$', name):\n",
    "            features[\"ends_in_vowel\"] = True\n",
    "        else:\n",
    "            features[\"ends_in_vowel\"] = False\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7004fa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822\n",
      "diff from previous: 0.044\n"
     ]
    }
   ],
   "source": [
    "train_set = apply_features(gender_features, train_names)\n",
    "devtest_set = apply_features(gender_features, dev_names)\n",
    "test_set = apply_features(gender_features, test_names)\n",
    "\n",
    "# train the classifier and test using devtest set \n",
    "v6_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "v6_score = nltk.classify.accuracy(v6_classifier, devtest_set)\n",
    "diff = round(v6_score - v5_score, 6)\n",
    "print(v6_score)\n",
    "print(\"diff from previous: {}\".format(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe958a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 0.776\n",
      "v2: 0.76\n",
      "v3: 0.79\n",
      "v4: 0.78\n",
      "v5: 0.778\n",
      "v6: 0.822\n",
      "best version: v6, 0.822\n"
     ]
    }
   ],
   "source": [
    "running_tally(v6_score, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692ef8d",
   "metadata": {},
   "source": [
    "An improvement. Although I have to note that this score has changed every time I have run the notebook. Let's see what happens if we change the feature to ending in two vowels. \n",
    "\n",
    "### Iteration: v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c74e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labeled_names)\n",
    "test_names, dev_names, train_names = labeled_names[:500], labeled_names[500:1000], labeled_names[1000:]\n",
    "\n",
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"suffix1\"] = name[-1:].lower()\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    features[\"syllables\"] = len(st.tokenize(name)) \n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    \n",
    "    for name in name:\n",
    "        if re.match('.+[aeiou][aeiou]$', name):\n",
    "            features[\"ends_in_dblvwl\"] = True\n",
    "        else:\n",
    "            features[\"ends_in_dblvwl\"] = False\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62efd83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792\n",
      "diff from previous: -0.03\n"
     ]
    }
   ],
   "source": [
    "train_set = apply_features(gender_features, train_names)\n",
    "devtest_set = apply_features(gender_features, dev_names)\n",
    "test_set = apply_features(gender_features, test_names)\n",
    "\n",
    "# train the classifier and test using devtest set \n",
    "v7_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "v7_score = nltk.classify.accuracy(v7_classifier, devtest_set)\n",
    "diff = round(v7_score - v6_score, 6)\n",
    "print(v7_score)\n",
    "print(\"diff from previous: {}\".format(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "870de781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 0.776\n",
      "v2: 0.76\n",
      "v3: 0.79\n",
      "v4: 0.78\n",
      "v5: 0.778\n",
      "v6: 0.822\n",
      "v7: 0.792\n",
      "best version: v6, 0.822\n"
     ]
    }
   ],
   "source": [
    "running_tally(v7_score, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a46a039",
   "metadata": {},
   "source": [
    "At this point I need to stress that every time I run these programs, I get different accuracy scores. In some iterations, v4 scores the highest. In others, v5. For this iteration I am going to use the v6 model on the test data to see how it performs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acad3fad",
   "metadata": {},
   "source": [
    "## Step 4: Check Performance Against Test Data\n",
    "\n",
    "Now we'll check the model performance against the v4 training features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b7c8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labeled_names)\n",
    "test_names, dev_names, train_names = labeled_names[:500], labeled_names[500:1000], labeled_names[1000:]\n",
    "\n",
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"suffix1\"] = name[-1:].lower()\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    features[\"syllables\"] = len(st.tokenize(name)) \n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    \n",
    "    for name in name:\n",
    "        if re.match('.+[aeiou]$', name):\n",
    "            features[\"ends_in_vowel\"] = True\n",
    "        else:\n",
    "            features[\"ends_in_vowel\"] = False\n",
    "\n",
    "    return features\n",
    "\n",
    "train_set = apply_features(gender_features, train_names)\n",
    "devtest_set = apply_features(gender_features, dev_names)\n",
    "test_set = apply_features(gender_features, test_names)\n",
    "\n",
    "# train the classifier and test using devtest set \n",
    "final_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "final_score = nltk.classify.accuracy(v7_classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78c048fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.822 \n",
      "Final score: 0.794\n"
     ]
    }
   ],
   "source": [
    "print(\"Test score: {} \\nFinal score: {}\".format(v6_score, final_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d4fb3",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In each iteration, I observed fluctuating accuracy scores each time I shuffled and split the data, which leads me to conclude that each model variation performs roughly the same, with about the same variance. If I were to continue to improve the model I would focus on removing some of the features to rely on the highest value predictors -- fewer predictors with higher significance will usually return predictions with lower variance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
